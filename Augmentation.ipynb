{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T11:56:03.430542Z",
     "start_time": "2020-04-30T11:56:00.314029Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install neural-structured-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T20:24:42.759425Z",
     "start_time": "2020-05-05T20:24:39.711980Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T20:24:55.980782Z",
     "start_time": "2020-05-05T20:24:50.315265Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install adversarial-robustness-toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T22:27:47.340028Z",
     "start_time": "2020-05-05T22:27:42.932249Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q pyyaml h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T10:29:52.242618Z",
     "start_time": "2020-05-07T10:29:52.064624Z"
    }
   },
   "outputs": [],
   "source": [
    "## from __future__ import absolute_import\n",
    "import matplotlib.pyplot as plt\n",
    "import neural_structured_learning as nsl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.preprocessing.image import array_to_img, img_to_array\n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "import pandas as pd\n",
    "# from tensorflow.keras.utils import np_utils\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "import random\n",
    "import math\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T10:55:05.791784Z",
     "start_time": "2020-05-06T10:55:05.665608Z"
    }
   },
   "outputs": [],
   "source": [
    "from art.defences import AdversarialTrainer\n",
    "from art.attacks import ProjectedGradientDescent\n",
    "from art.classifiers import TensorFlowClassifier\n",
    "from art.classifiers import TFClassifier, KerasClassifier\n",
    "from art.attacks import FastGradientMethod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T14:43:15.247026Z",
     "start_time": "2020-05-06T14:43:15.245054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T14:43:16.396453Z",
     "start_time": "2020-05-06T14:43:16.391453Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_string_in_list(match_list, string):\n",
    "    \"\"\"Return matching string fro   m a list of possible matches\"\"\"\n",
    "\n",
    "    # for possible_match in match_list:\n",
    "    for possible_match in match_list:\n",
    "        if possible_match in string:\n",
    "            return possible_match\n",
    "\n",
    "    return 'No matching label in list of possible matches'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T14:43:17.695006Z",
     "start_time": "2020-05-06T14:43:17.688049Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_images_and_labels(rootdir, possible_labels):\n",
    "    \"\"\"\n",
    "\n",
    "    Load and shuffle   the images and the labels from a directory. Assumes labels are given in the filenames.\n",
    "\n",
    "    rootdir (str) : the directory where the images are stored\n",
    "    possible_labels (list) : a list containing the possible labels of the task\n",
    "\n",
    "    \"\"\"\n",
    "    loaded_images = list()\n",
    "    labels = list()\n",
    "\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        for filename in files:\n",
    "            image = Image.open(subdir + '/' + filename)#.convert('L')\n",
    "            # image to array\n",
    "#             pixels = img_to_array(image)\n",
    "            pixels = image.resize((256, 256)) \n",
    "            # store loaded image\n",
    "            loaded_images.append(np.asarray(pixels))\n",
    "            # find label in filename and store label\n",
    "            labels.append(check_string_in_list(possible_labels, filename))\n",
    "\n",
    "#     labels = to_categorical(labels)\n",
    "    # normalize the images\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    labels = le.fit_transform(labels)\n",
    "    loaded_images = np.asarray(loaded_images)\n",
    "    loaded_images = (loaded_images - 127.5) / 127.5\n",
    "    labels = np.asarray(labels)\n",
    "    \n",
    "    # shuffle the images and labels\n",
    "    indices = np.arange(loaded_images.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    loaded_images = loaded_images[indices]\n",
    "    labels = labels[indices]\n",
    "    \n",
    "    print('Loaded {} images succesfully'.format(len(loaded_images)))\n",
    "    return loaded_images, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T16:43:30.933917Z",
     "start_time": "2020-05-06T16:43:30.926108Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 2907\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 16\n",
    "FOLDS= 2\n",
    "LEARN_RATE=0.0001\n",
    "LAYER_UNITS = (64, 16)\n",
    "TARGET_SIZE = (256, 256)\n",
    "TRAIN_SIZE = .7\n",
    "VAL_SIZE = .15\n",
    "TEST_SIZE = .15\n",
    "NUM_CLASSES = 6\n",
    "NUM_TRAIN_SAMPLES = TRAIN_SIZE * NUM_SAMPLES\n",
    "NUM_VAL_SAMPLES = VAL_SIZE * NUM_SAMPLES\n",
    "ROOTDIR = 'C:/Users/trist/Documents/GitHub/DeepLearningProject/dataset-split'\n",
    "possible_labels = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T17:49:02.347426Z",
     "start_time": "2020-05-04T17:49:00.369591Z"
    }
   },
   "outputs": [],
   "source": [
    "import split_folders\n",
    "split_folders.ratio('C:/Users/trist/Documents/GitHub/DeepLearningProject/dataset-resized', output=\"dataset-split\", seed=1337, ratio=(TRAIN_SIZE, VAL_SIZE, TEST_SIZE)) # default values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the base model and define the callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:42:01.920582Z",
     "start_time": "2020-05-06T20:42:01.912646Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_base_model(input_shape=(256, 256, 3)):\n",
    "     # build the VGG16 network\n",
    "    from tensorflow.keras.models import Model\n",
    "    densenet = DenseNet121(weights='imagenet',\n",
    "                               include_top=False,\n",
    "                               input_shape=input_shape)\n",
    "    \n",
    "    for layer in densenet.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # make batch normalization layers trainable to prevent overfitting\n",
    "    for layer in densenet.layers:\n",
    "        if \"BatchNormalization\" in layer.__class__.__name__:\n",
    "            layer.trainable = True\n",
    "            \n",
    "    x = densenet.output\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    for num_units in LAYER_UNITS:\n",
    "        x = Dense(num_units, activation='relu')(x)\n",
    "        x = Dropout(0.4)(x)\n",
    "\n",
    "    predictions = Dense(6, activation='softmax')(x)\n",
    "    custom_model = Model(inputs=densenet.input, outputs=predictions)\n",
    "   \n",
    "    return custom_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T15:36:56.483864Z",
     "start_time": "2020-05-06T15:36:56.479890Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_callbacks(name_weights, patience_lr):\n",
    "    mcp_save = ModelCheckpoint(name_weights, save_best_only=True, monitor='val_loss', mode='min')\n",
    "    reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=patience_lr, verbose=1, min_delta=1e-4, mode='min')\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    return [mcp_save, reduce_lr_loss]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create augmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T14:43:47.199379Z",
     "start_time": "2020-05-06T14:43:47.185415Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://github.com/zhunzhong07/Random-Erasing/blob/master/transforms.py\n",
    "#https://jkjung-avt.github.io/keras-image-cropping/\n",
    "\n",
    "def wrap_generator(batches, augmentation_type):\n",
    "    \"\"\"Take as input a Keras ImageGen (Iterator) and generate more augmentations\n",
    "    according to augmentor function.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_augmented = np.zeros((batch_x.shape[0], 256, 256, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            if augmentation_type is 'erase':\n",
    "                augmentor = RandomErasing()\n",
    "                batch_augmented[i] = augmentor(batch_x[i])\n",
    "            if augmentation_type is 'blend':\n",
    "                augmentor = MixingImages()\n",
    "                batch_augmented[i] = augmentor(batch_x[i], i, batch_x, batch_y)\n",
    "        yield (batch_augmented, batch_y)\n",
    "        \n",
    "class RandomErasing(object):\n",
    "    '''\n",
    "    Class that performs Random Erasing in Random Erasing Data Augmentation by Zhong et al. \n",
    "    -------------------------------------------------------------------------------------\n",
    "    probability: The probability that the operation will be performed.\n",
    "    sl: min erasing area\n",
    "    sh: max erasing area\n",
    "    r1: min aspect ratio\n",
    "    mean: erasing value\n",
    "    -------------------------------------------------------------------------------------\n",
    "    '''\n",
    "    def __init__(self, probability = 0.5, sl = 0.02, sh = 0.4, r1 = 0.3, mean=[0.4914, 0.4822, 0.4465]):\n",
    "        self.probability = probability\n",
    "        self.mean = mean\n",
    "        self.sl = sl\n",
    "        self.sh = sh\n",
    "        self.r1 = r1\n",
    "       \n",
    "    def __call__(self, img):\n",
    "\n",
    "        if random.uniform(0, 1) > self.probability:\n",
    "            return img\n",
    "\n",
    "        for attempt in range(100):\n",
    "            area = img.shape[1] * img.shape[2]\n",
    "            target_area = random.uniform(self.sl, self.sh) * area\n",
    "            aspect_ratio = random.uniform(self.r1, 1/self.r1)\n",
    "\n",
    "            h = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "            w = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "\n",
    "            if w < img.shape[2] and h < img.shape[1]:\n",
    "                x1 = random.randint(0, img.shape[1] - h)\n",
    "                y1 = random.randint(0, img.shape[2] - w)\n",
    "                if img.shape[0] == 3:\n",
    "                    img[0, x1:x1+h, y1:y1+w] = self.mean[0]\n",
    "                    img[1, x1:x1+h, y1:y1+w] = self.mean[1]\n",
    "                    img[2, x1:x1+h, y1:y1+w] = self.mean[2]\n",
    "                else:\n",
    "                    img[0, x1:x1+h, y1:y1+w] = self.mean[0]\n",
    "                return img\n",
    "\n",
    "        return img\n",
    "\n",
    "    \n",
    "class MixingImages(object):\n",
    "    '''\n",
    "    Class that performs Random mixing of images. \n",
    "    -------------------------------------------------------------------------------------\n",
    "    probability: The probability that the operation will be performed.\n",
    "    -------------------------------------------------------------------------------------\n",
    "    '''\n",
    "    def __init__(self, probability = 0.5, alpha=0.5):\n",
    "        self.probability = probability\n",
    "        self.alpha = alpha\n",
    "       \n",
    "    def __call__(self, img, i, batch_x, batch_y):\n",
    "\n",
    "        if random.uniform(0, 1) > self.probability:\n",
    "            return img\n",
    "        \n",
    "        options = [im for im, label in zip(batch_x, bach_y) if label == batch_y[i]]\n",
    "        img_to_blend = random.choice(options)\n",
    "        blended_img = Image.blend(img, img_to_blend, self.alpha) \n",
    "\n",
    "        return blended_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T15:27:26.397033Z",
     "start_time": "2020-05-06T15:27:26.386074Z"
    }
   },
   "outputs": [],
   "source": [
    "def new_train(ROOTDIR, TARGET_SIZE, EPOCHS, BATCH_SIZE, LEARN_RATE, NUM_TRAIN_SAMPLES, NUM_VAL_SAMPLES, datagen, \\\n",
    "              augmentation_type=None):\n",
    "    \n",
    "    # https://www.mlprojecttutorials.com/image%20recognition/transfer/\n",
    "    train_gen = datagen.flow_from_directory(\n",
    "        ROOTDIR + '/train', \n",
    "        target_size=TARGET_SIZE, \n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    val_gen = datagen.flow_from_directory(\n",
    "        ROOTDIR + '/val', \n",
    "        target_size=TARGET_SIZE, \n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    test_gen = datagen.flow_from_directory(\n",
    "        ROOTDIR + '/test', \n",
    "        target_size=TARGET_SIZE, \n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    name_weights = \"final_model\" + \"_weights.h5\"\n",
    "    callbacks = get_callbacks(name_weights = name_weights, patience_lr=10)\n",
    "#     tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "    optimizer = optimizers.Adam(lr=LEARN_RATE)\n",
    "    \n",
    "    if augmentation_type is 'erase' or augmentation_type is 'blend':\n",
    "        train_generator = wrap_generator(train_gen, augmentation_type)\n",
    "        val_generator = wrap_generator(val_gen, augmentation_type)\n",
    "\n",
    "        \n",
    "        model = build_base_model()\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "                   metrics=['acc'])\n",
    "      \n",
    "        model.fit_generator(\n",
    "                    train_generator,\n",
    "                    steps_per_epoch = int(NUM_TRAIN_SAMPLES // BATCH_SIZE), \n",
    "                    epochs=EPOCHS,\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps = int(NUM_VAL_SAMPLES // BATCH_SIZE),\n",
    "                    callbacks = callbacks)        \n",
    "\n",
    "    else:\n",
    "       \n",
    "        model = build_base_model()\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "                   metrics=['acc', 'AUC', 'Precision', 'Recall'])\n",
    "      \n",
    "        model.fit(\n",
    "                    train_gen,\n",
    "                    steps_per_epoch = int(NUM_TRAIN_SAMPLES // BATCH_SIZE), \n",
    "                    epochs=EPOCHS,\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    validation_data = val_gen,\n",
    "                    validation_steps = int(NUM_VAL_SAMPLES // BATCH_SIZE),\n",
    "                    callbacks = callbacks)\n",
    "        \n",
    "    return model, test_gen\n",
    "\n",
    "def evaluate_model(model, test_gen):    \n",
    "    filenames = test_gen.filenames\n",
    "    nb_samples = len(filenames)\n",
    "    \n",
    "    predictions = model.predict(test_gen, steps = nb_samples)\n",
    "    true_labels = test_gen.classes\n",
    "    \n",
    "    y_true = true_labels\n",
    "    y_pred = np.array([np.argmax(x) for x in predictions])\n",
    "\n",
    "    test_acc = sum(y_true == y_pred) / len(y_true)\n",
    "    print('Accuracy: {}'.format(test_acc))\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without any augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T16:58:55.610856Z",
     "start_time": "2020-05-06T16:43:37.639293Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2019 images belonging to 6 classes.\n",
      "Found 504 images belonging to 6 classes.\n",
      "Found 384 images belonging to 6 classes.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 127 steps, validate for 27 steps\n",
      "Epoch 1/20\n",
      "127/127 [==============================] - 86s 678ms/step - loss: 1.6474 - acc: 0.3140 - AUC: 0.6969 - val_loss: 1.4344 - val_acc: 0.4583 - val_AUC: 0.7851\n",
      "Epoch 2/20\n",
      "127/127 [==============================] - 61s 483ms/step - loss: 1.0287 - acc: 0.6176 - AUC: 0.8974 - val_loss: 1.2146 - val_acc: 0.5370 - val_AUC: 0.8488\n",
      "Epoch 3/20\n",
      "127/127 [==============================] - 61s 481ms/step - loss: 0.6565 - acc: 0.7732 - AUC: 0.9615 - val_loss: 1.0612 - val_acc: 0.6157 - val_AUC: 0.8874\n",
      "Epoch 4/20\n",
      "127/127 [==============================] - 61s 480ms/step - loss: 0.4161 - acc: 0.8826 - AUC: 0.9874 - val_loss: 1.0022 - val_acc: 0.6227 - val_AUC: 0.9001\n",
      "Epoch 5/20\n",
      "127/127 [==============================] - 59s 468ms/step - loss: 0.2650 - acc: 0.9351 - AUC: 0.9965 - val_loss: 1.0078 - val_acc: 0.6435 - val_AUC: 0.9024\n",
      "Epoch 6/20\n",
      "127/127 [==============================] - 62s 487ms/step - loss: 0.1721 - acc: 0.9693 - AUC: 0.9992 - val_loss: 0.9971 - val_acc: 0.6620 - val_AUC: 0.9073\n",
      "Epoch 7/20\n",
      "127/127 [==============================] - 66s 523ms/step - loss: 0.1142 - acc: 0.9896 - AUC: 0.9999 - val_loss: 0.9666 - val_acc: 0.6574 - val_AUC: 0.9129\n",
      "Epoch 8/20\n",
      "127/127 [==============================] - 60s 470ms/step - loss: 0.0811 - acc: 0.9965 - AUC: 1.0000 - val_loss: 0.9764 - val_acc: 0.6597 - val_AUC: 0.9127\n",
      "Epoch 9/20\n",
      "127/127 [==============================] - 60s 472ms/step - loss: 0.0583 - acc: 0.9980 - AUC: 1.0000 - val_loss: 1.0402 - val_acc: 0.6435 - val_AUC: 0.9070\n",
      "Epoch 10/20\n",
      "127/127 [==============================] - 60s 470ms/step - loss: 0.0434 - acc: 0.9995 - AUC: 1.0000 - val_loss: 1.0846 - val_acc: 0.6343 - val_AUC: 0.9038\n",
      "Epoch 11/20\n",
      "127/127 [==============================] - 60s 472ms/step - loss: 0.0346 - acc: 0.9995 - AUC: 1.0000 - val_loss: 1.0119 - val_acc: 0.6574 - val_AUC: 0.9131\n",
      "Epoch 12/20\n",
      "127/127 [==============================] - 60s 469ms/step - loss: 0.0274 - acc: 1.0000 - AUC: 1.0000 - val_loss: 1.0105 - val_acc: 0.6597 - val_AUC: 0.9143\n",
      "Epoch 13/20\n",
      "127/127 [==============================] - 49s 385ms/step - loss: 0.0227 - acc: 0.9995 - AUC: 1.0000 - val_loss: 1.0604 - val_acc: 0.6597 - val_AUC: 0.9108\n",
      "Epoch 14/20\n",
      "127/127 [==============================] - 13s 105ms/step - loss: 0.0188 - acc: 1.0000 - AUC: 1.0000 - val_loss: 1.0793 - val_acc: 0.6481 - val_AUC: 0.9107- loss: 0.0184 - acc: 1.0000 \n",
      "Epoch 15/20\n",
      "127/127 [==============================] - 13s 105ms/step - loss: 0.0161 - acc: 1.0000 - AUC: 1.0000 - val_loss: 1.0324 - val_acc: 0.6782 - val_AUC: 0.9158\n",
      "Epoch 16/20\n",
      "127/127 [==============================] - 13s 105ms/step - loss: 0.0136 - acc: 1.0000 - AUC: 1.0000 - val_loss: 1.0548 - val_acc: 0.6574 - val_AUC: 0.9146\n",
      "Epoch 17/20\n",
      "127/127 [==============================] - 13s 105ms/step - loss: 0.0118 - acc: 1.0000 - AUC: 1.0000 - val_loss: 1.0445 - val_acc: 0.6574 - val_AUC: 0.9169\n",
      "Epoch 18/20\n",
      "127/127 [==============================] - 13s 105ms/step - loss: 0.0103 - acc: 1.0000 - AUC: 1.0000 - val_loss: 1.0578 - val_acc: 0.6690 - val_AUC: 0.9142\n",
      "Epoch 19/20\n",
      "127/127 [==============================] - 13s 105ms/step - loss: 0.0091 - acc: 1.0000 - AUC: 1.0000 - val_loss: 1.0659 - val_acc: 0.6736 - val_AUC: 0.9146\n",
      "Epoch 20/20\n",
      "127/127 [==============================] - 13s 106ms/step - loss: 0.0080 - acc: 1.0000 - AUC: 1.0000 - val_loss: 1.0701 - val_acc: 0.6690 - val_AUC: 0.9151\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 384 batches). You may need to use the repeat() function when building your dataset.\n",
      "Accuracy: 0.6614583333333334\n"
     ]
    }
   ],
   "source": [
    "datagen_none = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "               )\n",
    "\n",
    "model, test_gen = new_train(ROOTDIR, TARGET_SIZE, EPOCHS, BATCH_SIZE, LEARN_RATE, NUM_TRAIN_SAMPLES, NUM_VAL_SAMPLES, datagen_none, \\\n",
    "              augmentation_type=None)\n",
    "\n",
    "model.save_weights('my_checkpoint')\n",
    "\n",
    "\n",
    "result = evaluate_model(model, test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With simple augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T21:01:32.386089Z",
     "start_time": "2020-05-06T20:42:11.022177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2019 images belonging to 6 classes.\n",
      "Found 504 images belonging to 6 classes.\n",
      "Found 384 images belonging to 6 classes.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 127 steps, validate for 27 steps\n",
      "Epoch 1/20\n",
      "127/127 [==============================] - 199s 2s/step - loss: 1.9815 - acc: 0.2100 - AUC: 0.5655 - val_loss: 1.7069 - val_acc: 0.2801 - val_AUC: 0.6594\n",
      "Epoch 2/20\n",
      "127/127 [==============================] - 152s 1s/step - loss: 1.7306 - acc: 0.2566 - AUC: 0.6299 - val_loss: 1.5844 - val_acc: 0.4259 - val_AUC: 0.7562\n",
      "Epoch 3/20\n",
      "127/127 [==============================] - 152s 1s/step - loss: 1.6832 - acc: 0.2888 - AUC: 0.6576 - val_loss: 1.5138 - val_acc: 0.4560 - val_AUC: 0.7713\n",
      "Epoch 4/20\n",
      "127/127 [==============================] - 46s 358ms/step - loss: 1.5719 - acc: 0.3289 - AUC: 0.7203 - val_loss: 1.3798 - val_acc: 0.5255 - val_AUC: 0.8280\n",
      "Epoch 5/20\n",
      "127/127 [==============================] - 35s 274ms/step - loss: 1.5469 - acc: 0.3447 - AUC: 0.7344 - val_loss: 1.3200 - val_acc: 0.5394 - val_AUC: 0.8519\n",
      "Epoch 6/20\n",
      "127/127 [==============================] - 35s 275ms/step - loss: 1.4998 - acc: 0.3928 - AUC: 0.7518 - val_loss: 1.2640 - val_acc: 0.5394 - val_AUC: 0.8524\n",
      "Epoch 7/20\n",
      "127/127 [==============================] - 35s 278ms/step - loss: 1.4765 - acc: 0.3928 - AUC: 0.7590 - val_loss: 1.2161 - val_acc: 0.5648 - val_AUC: 0.8688\n",
      "Epoch 8/20\n",
      "127/127 [==============================] - 37s 289ms/step - loss: 1.4324 - acc: 0.4007 - AUC: 0.7795 - val_loss: 1.1084 - val_acc: 0.6134 - val_AUC: 0.8917\n",
      "Epoch 9/20\n",
      "127/127 [==============================] - 38s 297ms/step - loss: 1.4022 - acc: 0.4240 - AUC: 0.7908 - val_loss: 1.0773 - val_acc: 0.6898 - val_AUC: 0.9035\n",
      "Epoch 10/20\n",
      "127/127 [==============================] - 37s 292ms/step - loss: 1.3425 - acc: 0.4453 - AUC: 0.8099 - val_loss: 1.0337 - val_acc: 0.6968 - val_AUC: 0.9138\n",
      "Epoch 11/20\n",
      "127/127 [==============================] - 37s 290ms/step - loss: 1.3046 - acc: 0.4611 - AUC: 0.8188 - val_loss: 1.0252 - val_acc: 0.6991 - val_AUC: 0.9092\n",
      "Epoch 12/20\n",
      "127/127 [==============================] - 37s 292ms/step - loss: 1.2864 - acc: 0.4789 - AUC: 0.8271 - val_loss: 0.9705 - val_acc: 0.7199 - val_AUC: 0.9236\n",
      "Epoch 13/20\n",
      "127/127 [==============================] - 37s 290ms/step - loss: 1.2573 - acc: 0.4804 - AUC: 0.8355 - val_loss: 0.9489 - val_acc: 0.7106 - val_AUC: 0.9247\n",
      "Epoch 14/20\n",
      "127/127 [==============================] - 37s 290ms/step - loss: 1.2673 - acc: 0.4933 - AUC: 0.8334 - val_loss: 0.9408 - val_acc: 0.7338 - val_AUC: 0.9295\n",
      "Epoch 15/20\n",
      "127/127 [==============================] - 36s 284ms/step - loss: 1.2506 - acc: 0.4933 - AUC: 0.8397 - val_loss: 0.9424 - val_acc: 0.7060 - val_AUC: 0.9257\n",
      "Epoch 16/20\n",
      "127/127 [==============================] - 37s 292ms/step - loss: 1.1595 - acc: 0.5290 - AUC: 0.8608 - val_loss: 0.8788 - val_acc: 0.7176 - val_AUC: 0.9340\n",
      "Epoch 17/20\n",
      "127/127 [==============================] - 37s 290ms/step - loss: 1.2103 - acc: 0.4998 - AUC: 0.8497 - val_loss: 0.8479 - val_acc: 0.7523 - val_AUC: 0.9425\n",
      "Epoch 18/20\n",
      "127/127 [==============================] - 37s 290ms/step - loss: 1.1564 - acc: 0.5537 - AUC: 0.8616 - val_loss: 0.8302 - val_acc: 0.7616 - val_AUC: 0.9433\n",
      "Epoch 19/20\n",
      "127/127 [==============================] - 37s 291ms/step - loss: 1.1540 - acc: 0.5389 - AUC: 0.8637 - val_loss: 0.8190 - val_acc: 0.7708 - val_AUC: 0.9450\n",
      "Epoch 20/20\n",
      "127/127 [==============================] - 37s 291ms/step - loss: 1.1596 - acc: 0.5349 - AUC: 0.8623 - val_loss: 0.8075 - val_acc: 0.7731 - val_AUC: 0.9453\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 384 batches). You may need to use the repeat() function when building your dataset.\n",
      "Accuracy: 0.7526041666666666\n"
     ]
    }
   ],
   "source": [
    "datagen_simple = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                rotation_range=20,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                horizontal_flip=True)\n",
    "\n",
    "model, test_gen = new_train(ROOTDIR, TARGET_SIZE, EPOCHS, BATCH_SIZE, LEARN_RATE, NUM_TRAIN_SAMPLES, NUM_VAL_SAMPLES, datagen_simple, \\\n",
    "              augmentation_type='simple')\n",
    "\n",
    "result = evaluate_model(model, test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Random Erasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T14:59:35.293419Z",
     "start_time": "2020-05-06T14:57:24.332265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2019 images belonging to 6 classes.\n",
      "Found 504 images belonging to 6 classes.\n",
      "Found 384 images belonging to 6 classes.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:From <ipython-input-14-f86cbc606ff1>:45: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 63 steps, validate for 13 steps\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 18s 293ms/step - loss: 1.3823 - acc: 0.5025 - val_loss: 1.2022 - val_acc: 0.5745\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 14s 216ms/step - loss: 0.8249 - acc: 0.7056 - val_loss: 1.0004 - val_acc: 0.5735\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 11s 181ms/step - loss: 0.5681 - acc: 0.8113 - val_loss: 1.0308 - val_acc: 0.6078\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 12s 190ms/step - loss: 0.4419 - acc: 0.8681 - val_loss: 0.9611 - val_acc: 0.6740\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 11s 173ms/step - loss: 0.3384 - acc: 0.8998 - val_loss: 1.1655 - val_acc: 0.6397\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 11s 174ms/step - loss: 0.2755 - acc: 0.9149 - val_loss: 0.9757 - val_acc: 0.6779\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 12s 189ms/step - loss: 0.2646 - acc: 0.9220 - val_loss: 0.8712 - val_acc: 0.7230\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 11s 174ms/step - loss: 0.2017 - acc: 0.9336 - val_loss: 0.9031 - val_acc: 0.7132\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 11s 174ms/step - loss: 0.1737 - acc: 0.9396 - val_loss: 0.9058 - val_acc: 0.6971\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 12s 185ms/step - loss: 0.1744 - acc: 0.9426 - val_loss: 0.8434 - val_acc: 0.7230\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 384 batches). You may need to use the repeat() function when building your dataset.\n",
      "Accuracy: 0.6614583333333334\n"
     ]
    }
   ],
   "source": [
    "datagen_none = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "               )\n",
    "\n",
    "model, test_gen = new_train(ROOTDIR, TARGET_SIZE, EPOCHS, BATCH_SIZE, LEARN_RATE, NUM_TRAIN_SAMPLES, NUM_VAL_SAMPLES, datagen_none, \\\n",
    "              augmentation_type='erase')\n",
    "\n",
    "result = evaluate_model(model, test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T15:01:49.528749Z",
     "start_time": "2020-05-06T14:59:44.870701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2019 images belonging to 6 classes.\n",
      "Found 504 images belonging to 6 classes.\n",
      "Found 384 images belonging to 6 classes.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 63 steps, validate for 13 steps\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 18s 285ms/step - loss: 1.1365 - acc: 0.6054 - val_loss: 0.9381 - val_acc: 0.6442\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 11s 178ms/step - loss: 0.4342 - acc: 0.8651 - val_loss: 0.8248 - val_acc: 0.6899\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 11s 177ms/step - loss: 0.1955 - acc: 0.9512 - val_loss: 0.7439 - val_acc: 0.7260\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 11s 179ms/step - loss: 0.1022 - acc: 0.9834 - val_loss: 0.7349 - val_acc: 0.7284\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 11s 182ms/step - loss: 0.0597 - acc: 0.9945 - val_loss: 0.7121 - val_acc: 0.7404\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 11s 170ms/step - loss: 0.0402 - acc: 0.9980 - val_loss: 0.7674 - val_acc: 0.7404\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 11s 169ms/step - loss: 0.0303 - acc: 0.9975 - val_loss: 0.8015 - val_acc: 0.7308\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 11s 169ms/step - loss: 0.0199 - acc: 0.9985 - val_loss: 0.8170 - val_acc: 0.7260\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 11s 169ms/step - loss: 0.0142 - acc: 0.9990 - val_loss: 0.8306 - val_acc: 0.7212\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 11s 168ms/step - loss: 0.0116 - acc: 0.9990 - val_loss: 0.7932 - val_acc: 0.7428\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 384 batches). You may need to use the repeat() function when building your dataset.\n",
      "Accuracy: 0.7213541666666666\n"
     ]
    }
   ],
   "source": [
    "datagen_none = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "               )\n",
    "\n",
    "model, test_gen = new_train(ROOTDIR, TARGET_SIZE, EPOCHS, BATCH_SIZE, LEARN_RATE, NUM_TRAIN_SAMPLES, NUM_VAL_SAMPLES, datagen_none, \\\n",
    "              augmentation_type='blending')\n",
    "\n",
    "result = evaluate_model(model, test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T14:47:18.490152Z",
     "start_time": "2020-05-04T14:47:11.315783Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = load_images_and_labels(rootdir, possible_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T17:37:58.263609Z",
     "start_time": "2020-05-04T17:37:58.251585Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(X, y, epochs, batch_size, folds, gen, learn_rate, augmentation_type=None):\n",
    "    print('creating folds')\n",
    "    folds = list(StratifiedKFold(n_splits=folds, shuffle=True, random_state=1).split(X, y))\n",
    "    print('started learning')\n",
    "\n",
    "#     metrics = pd.DataFrame()\n",
    "#     df.loc[len(df)] = [1,2,3]\n",
    "    metrics = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(folds):\n",
    "        \n",
    "        print('\\nFold ', fold)\n",
    "        X_train_cv = X[train_idx]\n",
    "        y_train_cv = y[train_idx]\n",
    "        X_valid_cv = X[val_idx]\n",
    "        y_valid_cv= y[val_idx]\n",
    "        \n",
    "        y_train_cv = np_utils.to_categorical(y_train_cv)\n",
    "        y_valid_cv = np_utils.to_categorical(y_valid_cv)\n",
    "        \n",
    "        name_weights = \"final_model_fold\" + str(fold) + \"_weights.h5\"\n",
    "        callbacks = get_callbacks(name_weights = name_weights, patience_lr=10)\n",
    "        \n",
    "        model = build_base_model((y_train_cv[0]).shape[0])\n",
    "        optimizer = optimizers.Adam(lr=0.0001)\n",
    "        \n",
    "        if augmentation_type is 'adverserial':\n",
    "            model = wrap_adverserial(model)\n",
    "            model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "                       metrics=['acc'])\n",
    "            model.fit(x={'input': X_train_cv, 'label': y_train_cv}, batch_size=batch_size)\n",
    "        \n",
    "        else:\n",
    "            generator = gen.flow(X_train_cv, y_train_cv, batch_size = batch_size, )\n",
    "\n",
    "            model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "                       metrics=['acc'])\n",
    "            \n",
    "            print(model.summary())\n",
    "            \n",
    "            model.fit_generator(\n",
    "                        generator,\n",
    "                        steps_per_epoch=len(X_train_cv)/batch_size,\n",
    "                        epochs=epochs,\n",
    "                        shuffle=True,\n",
    "                        verbose=1,\n",
    "                        validation_data = (X_valid_cv, y_valid_cv),\n",
    "                        callbacks = callbacks)\n",
    "\n",
    "        evaluation = model.evaluate(X_valid_cv, y_valid_cv)\n",
    "#         metrics = metrics.loc[len(df)] = evaluation\n",
    "        print(evaluation)\n",
    "        metrics.append(evaluation)\n",
    "\n",
    "        \n",
    "    return metrics\n",
    "        \n",
    "\n",
    "def wrap_adverserial(model):\n",
    "    adv_config = nsl.configs.make_adv_reg_config(\n",
    "        multiplier = 0.2,\n",
    "        adv_step_size = 0.2,\n",
    "        adv_grad_norm = 'infinity'\n",
    "    )\n",
    "    adv_model = nsl.keras.AdversarialRegularization(model,\n",
    "                                            label_keys=['label'],\n",
    "                                            adv_config=adv_config)\n",
    "    return adv_model\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
