{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T11:56:03.430542Z",
     "start_time": "2020-04-30T11:56:00.314029Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install neural-structured-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T20:24:42.759425Z",
     "start_time": "2020-05-05T20:24:39.711980Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T20:24:55.980782Z",
     "start_time": "2020-05-05T20:24:50.315265Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install adversarial-robustness-toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T22:27:47.340028Z",
     "start_time": "2020-05-05T22:27:42.932249Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q pyyaml h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T15:35:29.130408Z",
     "start_time": "2020-05-06T15:35:29.123427Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "import matplotlib.pyplot as plt\n",
    "import neural_structured_learning as nsl\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.preprocessing.image import array_to_img, img_to_array\n",
    "import os\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers\n",
    "import pandas as pd\n",
    "# from tensorflow.keras.utils import np_utils\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "import random\n",
    "import math\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T10:55:05.791784Z",
     "start_time": "2020-05-06T10:55:05.665608Z"
    }
   },
   "outputs": [],
   "source": [
    "from art.defences import AdversarialTrainer\n",
    "from art.attacks import ProjectedGradientDescent\n",
    "from art.classifiers import TensorFlowClassifier\n",
    "from art.classifiers import TFClassifier, KerasClassifier\n",
    "from art.attacks import FastGradientMethod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T14:43:15.247026Z",
     "start_time": "2020-05-06T14:43:15.245054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T14:43:16.396453Z",
     "start_time": "2020-05-06T14:43:16.391453Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_string_in_list(match_list, string):\n",
    "    \"\"\"Return matching string fro   m a list of possible matches\"\"\"\n",
    "\n",
    "    # for possible_match in match_list:\n",
    "    for possible_match in match_list:\n",
    "        if possible_match in string:\n",
    "            return possible_match\n",
    "\n",
    "    return 'No matching label in list of possible matches'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T14:43:17.695006Z",
     "start_time": "2020-05-06T14:43:17.688049Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_images_and_labels(rootdir, possible_labels):\n",
    "    \"\"\"\n",
    "\n",
    "    Load and shuffle   the images and the labels from a directory. Assumes labels are given in the filenames.\n",
    "\n",
    "    rootdir (str) : the directory where the images are stored\n",
    "    possible_labels (list) : a list containing the possible labels of the task\n",
    "\n",
    "    \"\"\"\n",
    "    loaded_images = list()\n",
    "    labels = list()\n",
    "\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        for filename in files:\n",
    "            image = Image.open(subdir + '/' + filename)#.convert('L')\n",
    "            # image to array\n",
    "#             pixels = img_to_array(image)\n",
    "            pixels = image.resize((256, 256)) \n",
    "            # store loaded image\n",
    "            loaded_images.append(np.asarray(pixels))\n",
    "            # find label in filename and store label\n",
    "            labels.append(check_string_in_list(possible_labels, filename))\n",
    "\n",
    "#     labels = to_categorical(labels)\n",
    "    # normalize the images\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    labels = le.fit_transform(labels)\n",
    "    loaded_images = np.asarray(loaded_images)\n",
    "    loaded_images = (loaded_images - 127.5) / 127.5\n",
    "    labels = np.asarray(labels)\n",
    "    \n",
    "    # shuffle the images and labels\n",
    "    indices = np.arange(loaded_images.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    loaded_images = loaded_images[indices]\n",
    "    labels = labels[indices]\n",
    "    \n",
    "    print('Loaded {} images succesfully'.format(len(loaded_images)))\n",
    "    return loaded_images, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T16:43:30.933917Z",
     "start_time": "2020-05-06T16:43:30.926108Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 2907\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 16\n",
    "FOLDS= 2\n",
    "LEARN_RATE=0.0001\n",
    "LAYER_UNITS = (64, 16)\n",
    "TARGET_SIZE = (256, 256)\n",
    "TRAIN_SIZE = .7\n",
    "VAL_SIZE = .15\n",
    "TEST_SIZE = .15\n",
    "NUM_CLASSES = 6\n",
    "NUM_TRAIN_SAMPLES = TRAIN_SIZE * NUM_SAMPLES\n",
    "NUM_VAL_SAMPLES = VAL_SIZE * NUM_SAMPLES\n",
    "ROOTDIR = 'C:/Users/trist/Documents/GitHub/DeepLearningProject/dataset-split'\n",
    "possible_labels = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T17:49:02.347426Z",
     "start_time": "2020-05-04T17:49:00.369591Z"
    }
   },
   "outputs": [],
   "source": [
    "import split_folders\n",
    "split_folders.ratio('C:/Users/trist/Documents/GitHub/DeepLearningProject/dataset-resized', output=\"dataset-split\", seed=1337, ratio=(TRAIN_SIZE, VAL_SIZE, TEST_SIZE)) # default values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the base model and define the callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T20:42:01.920582Z",
     "start_time": "2020-05-06T20:42:01.912646Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_base_model(input_shape=(256, 256, 3)):\n",
    "     # build the VGG16 network\n",
    "    from tensorflow.keras.models import Model\n",
    "    densenet = DenseNet121(weights='imagenet',\n",
    "                               include_top=False,\n",
    "                               input_shape=input_shape)\n",
    "    \n",
    "    for layer in densenet.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # make batch normalization layers trainable to prevent overfitting\n",
    "    for layer in densenet.layers:\n",
    "        if \"BatchNormalization\" in layer.__class__.__name__:\n",
    "            layer.trainable = True\n",
    "            \n",
    "    x = densenet.output\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    for num_units in LAYER_UNITS:\n",
    "        x = Dense(num_units, activation='relu')(x)\n",
    "        x = Dropout(0.4)(x)\n",
    "\n",
    "    predictions = Dense(6, activation='softmax')(x)\n",
    "    custom_model = Model(inputs=densenet.input, outputs=predictions)\n",
    "   \n",
    "    return custom_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T15:36:56.483864Z",
     "start_time": "2020-05-06T15:36:56.479890Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_callbacks(name_weights, patience_lr):\n",
    "    mcp_save = ModelCheckpoint(name_weights, save_best_only=True, monitor='val_loss', mode='min')\n",
    "    # reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=patience_lr, verbose=1, min_delta=1e-4, mode='min')\n",
    "    log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    return [mcp_save]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create augmentation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T14:43:47.199379Z",
     "start_time": "2020-05-06T14:43:47.185415Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://github.com/zhunzhong07/Random-Erasing/blob/master/transforms.py\n",
    "#https://jkjung-avt.github.io/keras-image-cropping/\n",
    "\n",
    "def wrap_generator(batches, augmentation_type):\n",
    "    \"\"\"Take as input a Keras ImageGen (Iterator) and generate more augmentations\n",
    "    according to augmentor function.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        batch_x, batch_y = next(batches)\n",
    "        batch_augmented = np.zeros((batch_x.shape[0], 256, 256, 3))\n",
    "        for i in range(batch_x.shape[0]):\n",
    "            if augmentation_type is 'erase':\n",
    "                augmentor = RandomErasing()\n",
    "                batch_augmented[i] = augmentor(batch_x[i])\n",
    "            if augmentation_type is 'blend':\n",
    "                augmentor = MixingImages()\n",
    "                batch_augmented[i] = augmentor(batch_x[i], i, batch_x, batch_y)\n",
    "        yield (batch_augmented, batch_y)\n",
    "        \n",
    "class RandomErasing(object):\n",
    "    '''\n",
    "    Class that performs Random Erasing in Random Erasing Data Augmentation by Zhong et al. \n",
    "    -------------------------------------------------------------------------------------\n",
    "    probability: The probability that the operation will be performed.\n",
    "    sl: min erasing area\n",
    "    sh: max erasing area\n",
    "    r1: min aspect ratio\n",
    "    mean: erasing value\n",
    "    -------------------------------------------------------------------------------------\n",
    "    '''\n",
    "    def __init__(self, probability = 0.5, sl = 0.02, sh = 0.4, r1 = 0.3, mean=[0.4914, 0.4822, 0.4465]):\n",
    "        self.probability = probability\n",
    "        self.mean = mean\n",
    "        self.sl = sl\n",
    "        self.sh = sh\n",
    "        self.r1 = r1\n",
    "       \n",
    "    def __call__(self, img):\n",
    "\n",
    "        if random.uniform(0, 1) > self.probability:\n",
    "            return img\n",
    "\n",
    "        for attempt in range(100):\n",
    "            area = img.shape[1] * img.shape[2]\n",
    "            target_area = random.uniform(self.sl, self.sh) * area\n",
    "            aspect_ratio = random.uniform(self.r1, 1/self.r1)\n",
    "\n",
    "            h = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "            w = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "\n",
    "            if w < img.shape[2] and h < img.shape[1]:\n",
    "                x1 = random.randint(0, img.shape[1] - h)\n",
    "                y1 = random.randint(0, img.shape[2] - w)\n",
    "                if img.shape[0] == 3:\n",
    "                    img[0, x1:x1+h, y1:y1+w] = self.mean[0]\n",
    "                    img[1, x1:x1+h, y1:y1+w] = self.mean[1]\n",
    "                    img[2, x1:x1+h, y1:y1+w] = self.mean[2]\n",
    "                else:\n",
    "                    img[0, x1:x1+h, y1:y1+w] = self.mean[0]\n",
    "                return img\n",
    "\n",
    "        return img\n",
    "\n",
    "    \n",
    "class MixingImages(object):\n",
    "    '''\n",
    "    Class that performs Random mixing of images. \n",
    "    -------------------------------------------------------------------------------------\n",
    "    probability: The probability that the operation will be performed.\n",
    "    -------------------------------------------------------------------------------------\n",
    "    '''\n",
    "    def __init__(self, probability = 0.5, alpha=0.5):\n",
    "        self.probability = probability\n",
    "        self.alpha = alpha\n",
    "       \n",
    "    def __call__(self, img, i, batch_x, batch_y):\n",
    "\n",
    "        if random.uniform(0, 1) > self.probability:\n",
    "            return img\n",
    "        \n",
    "        options = [im for im, label in zip(batch_x, bach_y) if label == batch_y[i]]\n",
    "        img_to_blend = random.choice(options)\n",
    "        blended_img = Image.blend(img, img_to_blend, self.alpha) \n",
    "\n",
    "        return blended_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T15:27:26.397033Z",
     "start_time": "2020-05-06T15:27:26.386074Z"
    }
   },
   "outputs": [],
   "source": [
    "def new_train(ROOTDIR, TARGET_SIZE, EPOCHS, BATCH_SIZE, LEARN_RATE, NUM_TRAIN_SAMPLES, NUM_VAL_SAMPLES, datagen, \\\n",
    "              augmentation_type=None):\n",
    "    \n",
    "    # https://www.mlprojecttutorials.com/image%20recognition/transfer/\n",
    "    train_gen = datagen.flow_from_directory(\n",
    "        ROOTDIR + '/train', \n",
    "        target_size=TARGET_SIZE, \n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    val_gen = datagen.flow_from_directory(\n",
    "        ROOTDIR + '/val', \n",
    "        target_size=TARGET_SIZE, \n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    test_gen = datagen.flow_from_directory(\n",
    "        ROOTDIR + '/test', \n",
    "        target_size=TARGET_SIZE, \n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    name_weights = \"final_model\" + \"_weights.h5\"\n",
    "    callbacks = get_callbacks(name_weights = name_weights, patience_lr=10)\n",
    "#     tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "    optimizer = optimizers.Adam(lr=LEARN_RATE)\n",
    "    \n",
    "    if augmentation_type is 'erase' or augmentation_type is 'blend':\n",
    "        train_generator = wrap_generator(train_gen, augmentation_type)\n",
    "        val_generator = wrap_generator(val_gen, augmentation_type)\n",
    "\n",
    "        \n",
    "        model = build_base_model()\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "                   metrics=['acc'])\n",
    "      \n",
    "        model.fit_generator(\n",
    "                    train_generator,\n",
    "                    steps_per_epoch = int(NUM_TRAIN_SAMPLES // BATCH_SIZE), \n",
    "                    epochs=EPOCHS,\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps = int(NUM_VAL_SAMPLES // BATCH_SIZE),\n",
    "                    callbacks = callbacks)        \n",
    "\n",
    "    else:\n",
    "       \n",
    "        model = build_base_model()\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "                   metrics=['acc', 'AUC', 'Precision', 'Recall'])\n",
    "      \n",
    "        model.fit(\n",
    "                    train_gen,\n",
    "                    steps_per_epoch = int(NUM_TRAIN_SAMPLES // BATCH_SIZE), \n",
    "                    epochs=EPOCHS,\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    validation_data = val_gen,\n",
    "                    validation_steps = int(NUM_VAL_SAMPLES // BATCH_SIZE),\n",
    "                    callbacks = callbacks)\n",
    "        \n",
    "    return model, test_gen\n",
    "\n",
    "def evaluate_model(model, test_gen):    \n",
    "    filenames = test_gen.filenames\n",
    "    nb_samples = len(filenames)\n",
    "    \n",
    "    predictions = model.predict(test_gen, steps = nb_samples)\n",
    "    true_labels = test_gen.classes\n",
    "    \n",
    "    y_true = true_labels\n",
    "    y_pred = np.array([np.argmax(x) for x in predictions])\n",
    "\n",
    "    test_acc = sum(y_true == y_pred) / len(y_true)\n",
    "    print('Accuracy: {}'.format(test_acc))\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform the experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without any augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T16:58:55.610856Z",
     "start_time": "2020-05-06T16:43:37.639293Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 2019 images belonging to 6 classes.\nFound 504 images belonging to 6 classes.\nFound 384 images belonging to 6 classes.\nWARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\nWARNING:tensorflow:sample_weight modes were coerced from\n  ...\n    to  \n  ['...']\nTrain for 127 steps, validate for 27 steps\nEpoch 1/20\n  1/127 [..............................] - ETA: 24:32WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
    },
    {
     "output_type": "error",
     "ename": "UnknownError",
     "evalue": "2 root error(s) found.\n  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model_1/conv1/conv/Conv2D (defined at <ipython-input-12-fb6dee9fb264>:61) ]]\n\t [[metrics/Recall/assert_less_equal/Assert/AssertGuard/pivot_f/_69/_97]]\n  (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model_1/conv1/conv/Conv2D (defined at <ipython-input-12-fb6dee9fb264>:61) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_66543]\n\nFunction call stack:\ndistributed_function -> distributed_function\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1c5067573685>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m model, test_gen = new_train(ROOTDIR, TARGET_SIZE, EPOCHS, BATCH_SIZE, LEARN_RATE, NUM_TRAIN_SAMPLES, NUM_VAL_SAMPLES, datagen_none, \\\n\u001b[1;32m----> 6\u001b[1;33m               augmentation_type=None)\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'my_checkpoint'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-fb6dee9fb264>\u001b[0m in \u001b[0;36mnew_train\u001b[1;34m(ROOTDIR, TARGET_SIZE, EPOCHS, BATCH_SIZE, LEARN_RATE, NUM_TRAIN_SAMPLES, NUM_VAL_SAMPLES, datagen, augmentation_type)\u001b[0m\n\u001b[0;32m     59\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNUM_VAL_SAMPLES\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                     callbacks = callbacks)\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_gen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: 2 root error(s) found.\n  (0) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model_1/conv1/conv/Conv2D (defined at <ipython-input-12-fb6dee9fb264>:61) ]]\n\t [[metrics/Recall/assert_less_equal/Assert/AssertGuard/pivot_f/_69/_97]]\n  (1) Unknown:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node model_1/conv1/conv/Conv2D (defined at <ipython-input-12-fb6dee9fb264>:61) ]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_distributed_function_66543]\n\nFunction call stack:\ndistributed_function -> distributed_function\n"
     ]
    }
   ],
   "source": [
    "datagen_none = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "               )\n",
    "\n",
    "model, test_gen = new_train(ROOTDIR, TARGET_SIZE, EPOCHS, BATCH_SIZE, LEARN_RATE, NUM_TRAIN_SAMPLES, NUM_VAL_SAMPLES, datagen_none, \\\n",
    "              augmentation_type=None)\n",
    "\n",
    "model.save_weights('my_checkpoint')\n",
    "\n",
    "\n",
    "result = evaluate_model(model, test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With simple augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T21:01:32.386089Z",
     "start_time": "2020-05-06T20:42:11.022177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2019 images belonging to 6 classes.\n",
      "Found 504 images belonging to 6 classes.\n",
      "Found 384 images belonging to 6 classes.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 127 steps, validate for 27 steps\n",
      "Epoch 1/20\n",
      "127/127 [==============================] - 199s 2s/step - loss: 1.9815 - acc: 0.2100 - AUC: 0.5655 - val_loss: 1.7069 - val_acc: 0.2801 - val_AUC: 0.6594\n",
      "Epoch 2/20\n",
      "127/127 [==============================] - 152s 1s/step - loss: 1.7306 - acc: 0.2566 - AUC: 0.6299 - val_loss: 1.5844 - val_acc: 0.4259 - val_AUC: 0.7562\n",
      "Epoch 3/20\n",
      "127/127 [==============================] - 152s 1s/step - loss: 1.6832 - acc: 0.2888 - AUC: 0.6576 - val_loss: 1.5138 - val_acc: 0.4560 - val_AUC: 0.7713\n",
      "Epoch 4/20\n",
      "127/127 [==============================] - 46s 358ms/step - loss: 1.5719 - acc: 0.3289 - AUC: 0.7203 - val_loss: 1.3798 - val_acc: 0.5255 - val_AUC: 0.8280\n",
      "Epoch 5/20\n",
      "127/127 [==============================] - 35s 274ms/step - loss: 1.5469 - acc: 0.3447 - AUC: 0.7344 - val_loss: 1.3200 - val_acc: 0.5394 - val_AUC: 0.8519\n",
      "Epoch 6/20\n",
      "127/127 [==============================] - 35s 275ms/step - loss: 1.4998 - acc: 0.3928 - AUC: 0.7518 - val_loss: 1.2640 - val_acc: 0.5394 - val_AUC: 0.8524\n",
      "Epoch 7/20\n",
      "127/127 [==============================] - 35s 278ms/step - loss: 1.4765 - acc: 0.3928 - AUC: 0.7590 - val_loss: 1.2161 - val_acc: 0.5648 - val_AUC: 0.8688\n",
      "Epoch 8/20\n",
      "127/127 [==============================] - 37s 289ms/step - loss: 1.4324 - acc: 0.4007 - AUC: 0.7795 - val_loss: 1.1084 - val_acc: 0.6134 - val_AUC: 0.8917\n",
      "Epoch 9/20\n",
      "127/127 [==============================] - 38s 297ms/step - loss: 1.4022 - acc: 0.4240 - AUC: 0.7908 - val_loss: 1.0773 - val_acc: 0.6898 - val_AUC: 0.9035\n",
      "Epoch 10/20\n",
      "127/127 [==============================] - 37s 292ms/step - loss: 1.3425 - acc: 0.4453 - AUC: 0.8099 - val_loss: 1.0337 - val_acc: 0.6968 - val_AUC: 0.9138\n",
      "Epoch 11/20\n",
      "127/127 [==============================] - 37s 290ms/step - loss: 1.3046 - acc: 0.4611 - AUC: 0.8188 - val_loss: 1.0252 - val_acc: 0.6991 - val_AUC: 0.9092\n",
      "Epoch 12/20\n",
      "127/127 [==============================] - 37s 292ms/step - loss: 1.2864 - acc: 0.4789 - AUC: 0.8271 - val_loss: 0.9705 - val_acc: 0.7199 - val_AUC: 0.9236\n",
      "Epoch 13/20\n",
      "127/127 [==============================] - 37s 290ms/step - loss: 1.2573 - acc: 0.4804 - AUC: 0.8355 - val_loss: 0.9489 - val_acc: 0.7106 - val_AUC: 0.9247\n",
      "Epoch 14/20\n",
      "127/127 [==============================] - 37s 290ms/step - loss: 1.2673 - acc: 0.4933 - AUC: 0.8334 - val_loss: 0.9408 - val_acc: 0.7338 - val_AUC: 0.9295\n",
      "Epoch 15/20\n",
      "127/127 [==============================] - 36s 284ms/step - loss: 1.2506 - acc: 0.4933 - AUC: 0.8397 - val_loss: 0.9424 - val_acc: 0.7060 - val_AUC: 0.9257\n",
      "Epoch 16/20\n",
      "127/127 [==============================] - 37s 292ms/step - loss: 1.1595 - acc: 0.5290 - AUC: 0.8608 - val_loss: 0.8788 - val_acc: 0.7176 - val_AUC: 0.9340\n",
      "Epoch 17/20\n",
      "127/127 [==============================] - 37s 290ms/step - loss: 1.2103 - acc: 0.4998 - AUC: 0.8497 - val_loss: 0.8479 - val_acc: 0.7523 - val_AUC: 0.9425\n",
      "Epoch 18/20\n",
      "127/127 [==============================] - 37s 290ms/step - loss: 1.1564 - acc: 0.5537 - AUC: 0.8616 - val_loss: 0.8302 - val_acc: 0.7616 - val_AUC: 0.9433\n",
      "Epoch 19/20\n",
      "127/127 [==============================] - 37s 291ms/step - loss: 1.1540 - acc: 0.5389 - AUC: 0.8637 - val_loss: 0.8190 - val_acc: 0.7708 - val_AUC: 0.9450\n",
      "Epoch 20/20\n",
      "127/127 [==============================] - 37s 291ms/step - loss: 1.1596 - acc: 0.5349 - AUC: 0.8623 - val_loss: 0.8075 - val_acc: 0.7731 - val_AUC: 0.9453\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 384 batches). You may need to use the repeat() function when building your dataset.\n",
      "Accuracy: 0.7526041666666666\n"
     ]
    }
   ],
   "source": [
    "datagen_simple = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                rotation_range=20,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                horizontal_flip=True)\n",
    "\n",
    "model, test_gen = new_train(ROOTDIR, TARGET_SIZE, EPOCHS, BATCH_SIZE, LEARN_RATE, NUM_TRAIN_SAMPLES, NUM_VAL_SAMPLES, datagen_simple, \\\n",
    "              augmentation_type='simple')\n",
    "\n",
    "result = evaluate_model(model, test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Random Erasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T14:59:35.293419Z",
     "start_time": "2020-05-06T14:57:24.332265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2019 images belonging to 6 classes.\n",
      "Found 504 images belonging to 6 classes.\n",
      "Found 384 images belonging to 6 classes.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:From <ipython-input-14-f86cbc606ff1>:45: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 63 steps, validate for 13 steps\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 18s 293ms/step - loss: 1.3823 - acc: 0.5025 - val_loss: 1.2022 - val_acc: 0.5745\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 14s 216ms/step - loss: 0.8249 - acc: 0.7056 - val_loss: 1.0004 - val_acc: 0.5735\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 11s 181ms/step - loss: 0.5681 - acc: 0.8113 - val_loss: 1.0308 - val_acc: 0.6078\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 12s 190ms/step - loss: 0.4419 - acc: 0.8681 - val_loss: 0.9611 - val_acc: 0.6740\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 11s 173ms/step - loss: 0.3384 - acc: 0.8998 - val_loss: 1.1655 - val_acc: 0.6397\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 11s 174ms/step - loss: 0.2755 - acc: 0.9149 - val_loss: 0.9757 - val_acc: 0.6779\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 12s 189ms/step - loss: 0.2646 - acc: 0.9220 - val_loss: 0.8712 - val_acc: 0.7230\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 11s 174ms/step - loss: 0.2017 - acc: 0.9336 - val_loss: 0.9031 - val_acc: 0.7132\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 11s 174ms/step - loss: 0.1737 - acc: 0.9396 - val_loss: 0.9058 - val_acc: 0.6971\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 12s 185ms/step - loss: 0.1744 - acc: 0.9426 - val_loss: 0.8434 - val_acc: 0.7230\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 384 batches). You may need to use the repeat() function when building your dataset.\n",
      "Accuracy: 0.6614583333333334\n"
     ]
    }
   ],
   "source": [
    "datagen_none = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "               )\n",
    "\n",
    "model, test_gen = new_train(ROOTDIR, TARGET_SIZE, EPOCHS, BATCH_SIZE, LEARN_RATE, NUM_TRAIN_SAMPLES, NUM_VAL_SAMPLES, datagen_none, \\\n",
    "              augmentation_type='erase')\n",
    "\n",
    "result = evaluate_model(model, test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T15:01:49.528749Z",
     "start_time": "2020-05-06T14:59:44.870701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2019 images belonging to 6 classes.\n",
      "Found 504 images belonging to 6 classes.\n",
      "Found 384 images belonging to 6 classes.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 63 steps, validate for 13 steps\n",
      "Epoch 1/10\n",
      "63/63 [==============================] - 18s 285ms/step - loss: 1.1365 - acc: 0.6054 - val_loss: 0.9381 - val_acc: 0.6442\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 11s 178ms/step - loss: 0.4342 - acc: 0.8651 - val_loss: 0.8248 - val_acc: 0.6899\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 11s 177ms/step - loss: 0.1955 - acc: 0.9512 - val_loss: 0.7439 - val_acc: 0.7260\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 11s 179ms/step - loss: 0.1022 - acc: 0.9834 - val_loss: 0.7349 - val_acc: 0.7284\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 11s 182ms/step - loss: 0.0597 - acc: 0.9945 - val_loss: 0.7121 - val_acc: 0.7404\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 11s 170ms/step - loss: 0.0402 - acc: 0.9980 - val_loss: 0.7674 - val_acc: 0.7404\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 11s 169ms/step - loss: 0.0303 - acc: 0.9975 - val_loss: 0.8015 - val_acc: 0.7308\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 11s 169ms/step - loss: 0.0199 - acc: 0.9985 - val_loss: 0.8170 - val_acc: 0.7260\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 11s 169ms/step - loss: 0.0142 - acc: 0.9990 - val_loss: 0.8306 - val_acc: 0.7212\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 11s 168ms/step - loss: 0.0116 - acc: 0.9990 - val_loss: 0.7932 - val_acc: 0.7428\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 384 batches). You may need to use the repeat() function when building your dataset.\n",
      "Accuracy: 0.7213541666666666\n"
     ]
    }
   ],
   "source": [
    "datagen_none = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "               )\n",
    "\n",
    "model, test_gen = new_train(ROOTDIR, TARGET_SIZE, EPOCHS, BATCH_SIZE, LEARN_RATE, NUM_TRAIN_SAMPLES, NUM_VAL_SAMPLES, datagen_none, \\\n",
    "              augmentation_type='blending')\n",
    "\n",
    "result = evaluate_model(model, test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T14:47:18.490152Z",
     "start_time": "2020-05-04T14:47:11.315783Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = load_images_and_labels(rootdir, possible_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T17:37:58.263609Z",
     "start_time": "2020-05-04T17:37:58.251585Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(X, y, epochs, batch_size, folds, gen, learn_rate, augmentation_type=None):\n",
    "    print('creating folds')\n",
    "    folds = list(StratifiedKFold(n_splits=folds, shuffle=True, random_state=1).split(X, y))\n",
    "    print('started learning')\n",
    "\n",
    "#     metrics = pd.DataFrame()\n",
    "#     df.loc[len(df)] = [1,2,3]\n",
    "    metrics = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(folds):\n",
    "        \n",
    "        print('\\nFold ', fold)\n",
    "        X_train_cv = X[train_idx]\n",
    "        y_train_cv = y[train_idx]\n",
    "        X_valid_cv = X[val_idx]\n",
    "        y_valid_cv= y[val_idx]\n",
    "        \n",
    "        y_train_cv = np_utils.to_categorical(y_train_cv)\n",
    "        y_valid_cv = np_utils.to_categorical(y_valid_cv)\n",
    "        \n",
    "        name_weights = \"final_model_fold\" + str(fold) + \"_weights.h5\"\n",
    "        callbacks = get_callbacks(name_weights = name_weights, patience_lr=10)\n",
    "        \n",
    "        model = build_base_model((y_train_cv[0]).shape[0])\n",
    "        optimizer = optimizers.Adam(lr=0.0001)\n",
    "        \n",
    "        if augmentation_type is 'adverserial':\n",
    "            model = wrap_adverserial(model)\n",
    "            model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "                       metrics=['acc'])\n",
    "            model.fit(x={'input': X_train_cv, 'label': y_train_cv}, batch_size=batch_size)\n",
    "        \n",
    "        else:\n",
    "            generator = gen.flow(X_train_cv, y_train_cv, batch_size = batch_size, )\n",
    "\n",
    "            model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "                       metrics=['acc'])\n",
    "            \n",
    "            print(model.summary())\n",
    "            \n",
    "            model.fit_generator(\n",
    "                        generator,\n",
    "                        steps_per_epoch=len(X_train_cv)/batch_size,\n",
    "                        epochs=epochs,\n",
    "                        shuffle=True,\n",
    "                        verbose=1,\n",
    "                        validation_data = (X_valid_cv, y_valid_cv),\n",
    "                        callbacks = callbacks)\n",
    "\n",
    "        evaluation = model.evaluate(X_valid_cv, y_valid_cv)\n",
    "#         metrics = metrics.loc[len(df)] = evaluation\n",
    "        print(evaluation)\n",
    "        metrics.append(evaluation)\n",
    "\n",
    "        \n",
    "    return metrics\n",
    "        \n",
    "\n",
    "def wrap_adverserial(model):\n",
    "    adv_config = nsl.configs.make_adv_reg_config(\n",
    "        multiplier = 0.2,\n",
    "        adv_step_size = 0.2,\n",
    "        adv_grad_norm = 'infinity'\n",
    "    )\n",
    "    adv_model = nsl.keras.AdversarialRegularization(model,\n",
    "                                            label_keys=['label'],\n",
    "                                            adv_config=adv_config)\n",
    "    return adv_model\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}